"""
ä¸€éµè¨“ç·´è…³æœ¬ - è‡ªå‹•è™•ç†æ‰€æœ‰æ­¥é©Ÿä¸¦ç”Ÿæˆ emotion_model.h5
"""
import os
os.environ['KERAS_BACKEND'] = 'torch'

import numpy as np
import keras
from PIL import Image
import sys

categories = ["happy", "angry", "sad", "surprised", "tired", "hungry", "confused", "love"]

print("=" * 60)
print("  å¥³æœ‹å‹è¡¨æƒ…è¾¨è­˜å™¨ - è‡ªå‹•è¨“ç·´è…³æœ¬")
print("=" * 60)

# è¼‰å…¥åœ–ç‰‡
print("\n[1/5] è¼‰å…¥è¨“ç·´åœ–ç‰‡...")
data, labels = [], []
total_images = 0

for i, cat in enumerate(categories):
    if not os.path.exists(cat):
        print(f"  âš ï¸  è³‡æ–™å¤¾ {cat} ä¸å­˜åœ¨")
        continue
    
    files = [f for f in os.listdir(cat) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    print(f"  âœ“ {cat}: {len(files)} å¼µ")
    total_images += len(files)
    
    for fname in files[:20]:  # é™åˆ¶æ¯é¡æœ€å¤š20å¼µåŠ é€Ÿ
        try:
            img = Image.open(os.path.join(cat, fname)).convert('RGB').resize((128, 128))  # æ”¹å°åŠ é€Ÿ
            data.append(np.array(img, dtype='float32') / 255.0)
            labels.append(i)
        except:
            pass

if len(data) == 0:
    print("\nâŒ æ²’æœ‰æ‰¾åˆ°åœ–ç‰‡ï¼è«‹ç¢ºèªç…§ç‰‡åœ¨æ­£ç¢ºçš„è³‡æ–™å¤¾ä¸­ã€‚")
    sys.exit(1)

data = np.array(data)
labels = keras.utils.to_categorical(labels, len(categories))
print(f"\n  âœ… æˆåŠŸè¼‰å…¥ {len(data)} å¼µåœ–ç‰‡")

# å»ºç«‹æ¨¡å‹
print("\n[2/5] å»ºç«‹ç¥ç¶“ç¶²è·¯æ¨¡å‹...")
model = keras.Sequential([
    keras.layers.Input(shape=(128, 128, 3)),
    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(64, 3, activation='relu', padding='same'),
    keras.layers.MaxPooling2D(2),
    keras.layers.Conv2D(128, 3, activation='relu', padding='same'),
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(len(categories), activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
print("  âœ… æ¨¡å‹å»ºç«‹å®Œæˆ")

# è¨“ç·´
print("\n[3/5] é–‹å§‹è¨“ç·´æ¨¡å‹...")
print("  ï¼ˆé€™å¯èƒ½éœ€è¦ 3-5 åˆ†é˜ï¼Œè«‹ç¨å€™...ï¼‰\n")

history = model.fit(
    data, labels,
    epochs=15,
    batch_size=4,
    validation_split=0.2,
    verbose=1
)

# å„²å­˜
print("\n[4/5] å„²å­˜æ¨¡å‹...")
model.save('emotion_model.h5')
print("  âœ… æ¨¡å‹å·²å„²å­˜ç‚º emotion_model.h5")

# æ¸¬è©¦
print("\n[5/5] é©—è­‰æ¨¡å‹...")
test_img = data[0:1]
prediction = model.predict(test_img, verbose=0)
predicted_class = np.argmax(prediction)
print(f"  âœ… æ¸¬è©¦æˆåŠŸï¼é æ¸¬é¡åˆ¥: {categories[predicted_class]}")

# é¡¯ç¤ºçµæœ
print("\n" + "=" * 60)
print("  ğŸ‰ è¨“ç·´å®Œæˆï¼")
print("=" * 60)
final_acc = history.history['accuracy'][-1]
final_val_acc = history.history['val_accuracy'][-1]
print(f"\n  è¨“ç·´æº–ç¢ºç‡: {final_acc*100:.1f}%")
print(f"  é©—è­‰æº–ç¢ºç‡: {final_val_acc*100:.1f}%")
print(f"\n  æ¨¡å‹æª”æ¡ˆ: emotion_model.h5")
print(f"  æª”æ¡ˆå¤§å°: {os.path.getsize('emotion_model.h5')/1024/1024:.1f} MB")
print("\n  ä¸‹ä¸€æ­¥ï¼š")
print("  1. è¨ªå• http://localhost:8501")
print("  2. åˆ°ã€Œä¸Šå‚³ç…§ç‰‡é€²è¡Œè¾¨è­˜ã€æ¨™ç±¤")
print("  3. ä¸Šå‚³ç…§ç‰‡æ¸¬è©¦æ•ˆæœï¼")
print("\n" + "=" * 60)
